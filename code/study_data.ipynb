{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Format misc\n",
    "import pickle\n",
    "\n",
    "#Combine sets and calculate diversity\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "#Plot\n",
    "import seaborn as sns\n",
    "import pylab as plt\n",
    "\n",
    "sns.set(font_scale=1.3)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colors\n",
    "palette = ((255/255,174/255,143/255),(111/255,158/255,206/255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_people_hap.csv already uncompressed\n"
     ]
    }
   ],
   "source": [
    "if not \"all_people_hap.csv\" in os.listdir(\"data_clean\"):\n",
    "    print(\"Uncompressing processed data, you can also download it directly running format_data.ipynb\")\n",
    "    !unzip -p 'data_clean/all_people_hap*.zip' | cat > data_clean/all_people_hap.csv\n",
    "else:\n",
    "    print(\"all_people_hap.csv already uncompressed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 30 fields in line 1967530, saw 42\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mParserError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3392e35eefa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Read the cleaned data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpeople\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_clean/all_people_hap.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#For now, delete after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mparties\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'AfD'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'Bündnis90/Die Grünen'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CDU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CSU'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'Die Linke'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'FDP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SPD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 30 fields in line 1967530, saw 42\n"
     ]
    }
   ],
   "source": [
    "#Read the cleaned data \n",
    "people = pd.read_csv(\"data_clean/all_people_hap.csv\",sep=\"\\t\")\n",
    "\n",
    "#For now, delete after\n",
    "parties = ['AfD',  'Bündnis90/Die Grünen', 'CDU', 'CSU',  'Die Linke',  'FDP', 'SPD']\n",
    "people[\"person\"] = people[\"keyword\"].apply(lambda x: x in parties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.read_csv(\"data_clean/all_people_entropy.csv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir figures\n",
    "\n",
    "ress = []\n",
    "for a,b in p.groupby(\"search_type\"):\n",
    "    print(a)\n",
    "    for d,h in b.groupby([\"keyword\"]):\n",
    "        print(d)\n",
    "        plt.figure(figsize=(5,3.5))\n",
    "        for j,h2 in h.groupby(\"login_status\"):\n",
    "            \n",
    "            if not j:\n",
    "                color=palette[0]\n",
    "            else:\n",
    "                color=palette[1]\n",
    "            sns.regplot(\"plugin_id\",\"result_hash\",data=h2,truncate=True,\n",
    "                        scatter_kws={\"s\":10,\"alpha\":0.5},lowess=True,color=color)#,y_partial=\"plugin_id\")         \n",
    "            \n",
    "                \n",
    "            plt.scatter([0,0],[0,0],label=str(j),color=color)\n",
    "                \n",
    "            plt.xlabel(\"Log10 number of people\")\n",
    "            plt.ylabel(\"Entropy\")\n",
    "            \n",
    "            \n",
    "            ress.append((a,d,h2))\n",
    "\n",
    "            \n",
    "        plt.xlim(1,3)\n",
    "        if a == \"search\":\n",
    "            plt.ylim(0.6,1)\n",
    "        else:\n",
    "            plt.ylim(0.8,1)\n",
    "        \n",
    "        \n",
    "        sns.despine()\n",
    "        plt.grid()\n",
    "        legend = plt.legend(title=\"Login status:\",fontsize=14)\n",
    "        plt.setp(legend.get_title(),fontsize='small')\n",
    "        plt.tight_layout()\n",
    "\n",
    "\n",
    "        if d == \"Alice Weidel\":\n",
    "            plt.savefig(\"figures/alice_{}.pdf\".format(a))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ideology between parties\n",
    "\n",
    "person2party_code = {'Alexander Gauland': 'AfD',\n",
    " 'Alice Weidel': 'AfD',\n",
    " 'Angela Merkel': 'CDU',\n",
    " 'Cem Özdemir': 'Grüne',\n",
    " 'Christian Lindner': 'FDP',\n",
    " 'Dietmar Bartsch': 'Linke',\n",
    " 'Katrin Göring-Eckardt': 'Grüne',\n",
    " 'Martin Schulz': 'SPD',\n",
    " 'Sahra Wagenknecht': 'Linke',\n",
    "                    'Bündnis90/Die Grünen': 'Grüne',\n",
    "                    'Die Linke': \"Linke\"}\n",
    "\n",
    "\n",
    "p_i = people.groupby([\"const_i\",\"keyword\",\"login_status\",\"search_type\"]).mean().reset_index()\n",
    "\n",
    "sns.clustermap(people.loc[people[\"search_type\"]==\"news\",[\"{}_ideo\".format(party) for party in [\"AfD\",\"CDU\",\"CSU\",\"FDP\",\"Grüne\",\"Linke\",\"SPD\"]]].fillna(0).corr(),\n",
    "           cmap=\"YlOrBr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Political personalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(df, n=1, axis=0):     \n",
    "    df = df.copy().reset_index()\n",
    "    del df[\"index\"]\n",
    "    for _ in range(n):\n",
    "        df.apply(np.random.shuffle, axis=axis)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for party in [\"AfD\",\"Linke\",\"FDP\",\"Grüne\",\"CDU\",\"CSU\",\"SPD\"]:\n",
    "    people[\"av_{}_ideo\".format(party)] = people.groupby([\"login_status\",\"search_type\",\"keyword\",\"const_i\"])[\"{}_ideo\".format(party)].transform(np.mean)\n",
    "    people[\"diff_{}_ideo\".format(party)] = people[\"{}_ideo\".format(party)] - people[\"av_{}_ideo\".format(party)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final1 = []\n",
    "final1_null = []\n",
    "#Robust to changes in person (party queries or people query, and to minimum number of articles (count_ideo_all))\n",
    "for l,data in people.loc[(people[\"person\"]==0)&(people[\"count_ideo_all\"]>1)].groupby([\"login_status\",\"search_type\"]):\n",
    "    for party in [\"AfD\",\"Linke\",\"FDP\",\"Grüne\",\"CDU\",\"CSU\",\"SPD\"]:\n",
    "        vals = \"diff_{}_ideo\".format(party)\n",
    "        #vals = \"diff_std_haps\"\n",
    "        data1 = data.loc[:,[vals,\"const_i\",\"keyword\",\"user\"]]\n",
    "#         cand = party2person.get(party)\n",
    "#         if cand is None:\n",
    "#             continue\n",
    "#         data1 = data1.loc[data1[\"keyword\"].isin(cand)]\n",
    "        all_keyword = pd.pivot_table(data1,values=vals,columns=\"keyword\",index=[\"const_i\",\"user\"]).replace([0,1],np.NaN)\n",
    "        persons = list(all_keyword.columns)\n",
    "        all_keyword = all_keyword.reset_index()\n",
    "        corr = []\n",
    "        corr_null = []\n",
    "        for k in range(len(persons)):\n",
    "            for j in range(k+1,len(persons)):\n",
    "                t = all_keyword[[\"const_i\",persons[k],persons[j]]].dropna()\n",
    "                #print(len(t))\n",
    "                #if len(t) > 1000:\n",
    "                c,p = pearsonr(t[persons[k]],t[persons[j]])\n",
    "                corr.append(c)\n",
    "                \n",
    "                \n",
    "                null = np.nan#pd.concat([shuffle(d) for x,d in t.groupby([\"const_i\"])])\n",
    "                c_null,p = np.nan,np.nan#pearsonr(null[persons[k]],null[persons[j]])\n",
    "                corr_null.append(c_null)\n",
    "        \n",
    "                final1.append(list(l)+[party]+corr)\n",
    "                final1_null.append(list(l)+[party]+corr_null)\n",
    "\n",
    "        print(party,l,np.mean(corr),np.mean(corr_null))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3.5))\n",
    "\n",
    "plt.subplot(1,1,1)\n",
    "x = pd.DataFrame(final1)\n",
    "x = pd.melt(x,id_vars=[0,1,2])\n",
    "\n",
    "sns.barplot(x=1,y=\"value\",hue=0,data=x,palette=palette,edgecolor=\"none\")\n",
    "\n",
    "sns.despine()\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Average correlation between\\n the ideology of results\")\n",
    "plt.xticks([0.,1.],[\"Google\\n News\",\"Google\\n Search\"])\n",
    "plt.ylim(-0.0,0.14)\n",
    "legend = plt.legend(fontsize=12)\n",
    "legend.set_title(\"Login status:\", prop = {'size':'small'})\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(\"figures/corr_ideo.pdf\".format(a))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(final1)\n",
    "x = pd.melt(x,id_vars=[0,1,2,3])\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.barplot(x=2,y=\"value\",hue=0,data=x.loc[x[1]==\"news\"])\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.barplot(x=2,y=\"value\",hue=0,data=x.loc[x[1]==\"search\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media = np.array([0.8,0.2])\n",
    "own_op = 1\n",
    "p = 0.\n",
    "## Model\n",
    "\n",
    "def update(x,w=None):\n",
    "    #return (own_op*x+x**b*np.mean(media))/(own_op+x**b*np.mean(media) + (1-x)**b*(1-np.mean(media)))\n",
    "    \n",
    "#     diffs = np.abs(media-x)\n",
    "#     f = np.abs(np.diff(diffs))[0]*slope\n",
    "#     w = np.array([0.5,0.5])\n",
    "#     w[diffs==np.min(diffs)] += f\n",
    "#     w[diffs==np.max(diffs)] -= f\n",
    "    if w is None:\n",
    "        w = 1-np.abs(x-media)\n",
    "        w = w/np.sum(w)\n",
    "#    w = 0.5\n",
    "    \n",
    "    #Linear increase\n",
    "    return (own_op*x+x**(b+p)*np.sum(media*w))/(own_op+x**(b+p)*np.sum(media*w) + (1-x)**(b+p)*(1-np.sum(media*w)))\n",
    " \n",
    "plt.figure(figsize=(10,3.5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "for b in [0.6,0.7,0.8,0.9,1,1.1]:# np.linspace(0,1.1,12):\n",
    "    x = [0.01,0.1,0.49,0.51,0.9,0.99]\n",
    "    v = []\n",
    "    for i in x:\n",
    "        for j in range(1000):\n",
    "            i = update(i,w=0.5)\n",
    "        v.append(i)\n",
    "    plt.grid()\n",
    "    plt.plot(x,v,label=str(b)[:4],color=(1.4-b,1.4-b,1.4-b),linewidth=2)\n",
    "    if b == 1:\n",
    "        plt.annotate(r\"$b=1$\",(0.9,0.8))\n",
    "    if b == 1.1:\n",
    "        plt.annotate(r\"$b>1$\",(0.9,1.05)) \n",
    "    if b == 0.6:\n",
    "        plt.annotate(r\"$b<1$\",(0.9,0.4))\n",
    "    #print(v[-2])\n",
    "# plt.legend(title=\"Assimilation bias\")\n",
    "sns.despine()\n",
    "plt.xlabel(\"Initial opinion\")\n",
    "plt.ylabel(\"Final opinion\")\n",
    "plt.title(\"(A): No personalization\")\n",
    "plt.ylim(0,1.1)\n",
    "plt.xlim(0,1.05)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "for b in [0.6,0.7,0.8,0.9,1,1.1]:# np.linspace(0,1.1,12):\n",
    "    x = [0.01,0.1,0.49,0.51,0.9,0.99]\n",
    "    v = []\n",
    "    for i in x:\n",
    "        for j in range(1000):\n",
    "            i = update(i)\n",
    "        v.append(i)\n",
    "    plt.grid()\n",
    "    plt.plot(x,v,label=str(b)[:3],color=(1.4-b,1.4-b,1.4-b),linewidth=2)\n",
    "\n",
    "\n",
    "plt.annotate(r\"$b=0.6$\",(1.,0.65))\n",
    "plt.annotate(r\"$b=0.7$\",(1,0.8))\n",
    "plt.annotate(r\"$b=0.8$\",(1,0.93))\n",
    "plt.annotate(r\"$b>0.8$\",(1,1.05))\n",
    "\n",
    "sns.despine()\n",
    "plt.xlabel(\"Initial opinion\")\n",
    "plt.ylabel(\"Final opinion\")\n",
    "plt.title(\"(B): Personalization\")\n",
    "plt.ylim(0,1.1)\n",
    "plt.xlim(0,1.15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/sim_polarization.pdf\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
